{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNEuw8i11WrbF3M0MXE2niM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qtEU-uP54AcN","executionInfo":{"status":"ok","timestamp":1676763575678,"user_tz":-360,"elapsed":6562,"user":{"displayName":"Aristotle Aletheia","userId":"18318552716161866746"}},"outputId":"aa20e890-1067-4d84-99bd-b77fbfbd94fa"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from transformers import BertTokenizer, BertModel\n","tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n","model = BertModel.from_pretrained(\"bert-large-cased\")\n","text = \"I love twice dahyun\"\n","encoded_input = tokenizer(text, return_tensors='pt')\n","output = model(**encoded_input)"]},{"cell_type":"code","source":[],"metadata":{"id":"LjWmTHn55ZeF"},"execution_count":null,"outputs":[]}]}