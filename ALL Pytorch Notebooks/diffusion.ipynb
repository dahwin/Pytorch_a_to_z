{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMaL/yXvgVzru4R3RxvrXUc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fVt3Xa4e6lXF"},"outputs":[],"source":["import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","import random\n","\n","# Load the dataset\n","data = torchvision.datasets.StanfordCars(root='.', download=True)\n","\n","# Show 20 random images from the dataset\n","fig, axs = plt.subplots(5, 5, figsize=(12, 9))\n","fig.tight_layout()\n","\n","for ax in axs.ravel():\n","    # Get a random image and label from the dataset\n","    idx = random.randint(0, len(data)-1)\n","    img, label = data[idx]\n","\n","    # Display the image and label\n","    ax.imshow(img)\n","    ax.set_title(f\"Class {label}\")\n","    ax.axis(\"off\")\n","\n","plt.show()\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","def linear_beta_schadule(timesteps,start=0.0001,end=0.02):\n","  return torch.linspace(start,end,timesteps)\n","linear_beta_schadule(0,10,2)\n","\n","\n","def get_index_from_list(vals, t, x_shape):\n","    \"\"\" \n","    Returns a specific index t of a passed list of values vals\n","    while considering the batch dimension.\n","    \"\"\"\n","    batch_size = t.shape[0]\n","    out = vals.gather(-1, t.cpu())\n","    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n","\n","def forward_diffusion_sample(x_0,t,device='cpu'):\n","  noise = torch.randn_like(x_0)\n","  sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape)\n","  sqrt_one_minus_alphas_cumprod_t = get_index_from_list(sqrt_one_minus_alphas_cumprod,t,x_0.shape)\n","\n","  # mean + variace\n","\n","  return sqrt_alphas_cumprod_t.to(device) * x_0.to(device) \\\n","  + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device),noise.to(device)\n","\n","\n","T = 300\n","betas = linear_beta_schadule(timesteps=T)\n","alphas = 1. -betas\n","alphas_cumprod = torch.cumprod(alphas,axis=0)\n","alphas_comprod_prev = F.pad(alphas_cumprod[:-1],(1,0),value=1.0)\n","sqrt_recip_alphas = torch.sqrt(1.0/alphas)\n","sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n","sqrt_one_minus_alphas_cumprod = torch.sqrt(1.-alphas_cumprod)\n","posterior_variance = betas *(1.-alphas_comprod_prev)/(1.-alphas_cumprod) \n"],"metadata":{"id":"3BWcJ-jFct_7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","import numpy as np\n","IMG_SIZE = 64\n","BATCH_SIZE = 128\n","def load_transformed_dataset():\n","    data_transforms = [\n","        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(), # Scales data into [0,1] \n","        transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1] \n","    ]\n","    data_transform = transforms.Compose(data_transforms)\n","\n","    train = torchvision.datasets.StanfordCars(root=\".\", download=True, \n","                                         transform=data_transform)\n","\n","    test = torchvision.datasets.StanfordCars(root=\".\", download=True, \n","                                         transform=data_transform, split='test')\n","    return torch.utils.data.ConcatDataset([train, test])\n","\n","def show_tensor_image(image):\n","    reverse_transforms = transforms.Compose([\n","        transforms.Lambda(lambda t: (t + 1) / 2),\n","        transforms.Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n","        transforms.Lambda(lambda t: t * 255.),\n","        transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n","        transforms.ToPILImage(),\n","    ])\n","\n","    # Take first image of batch\n","    if len(image.shape) == 4:\n","        image = image[0, :, :, :] \n","    plt.imshow(reverse_transforms(image))\n","\n","data = load_transformed_dataset()\n","dataloader = DataLoader(data,BATCH_SIZE,shuffle=True,drop_last=True)\n"],"metadata":{"id":"cES2uQ1dR7wP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = next(iter(dataloader))[0]\n","plt.figure(figsize=(15,15))\n","plt.axis('off')\n","num_images = 10\n","stepsize = int(T/num_images)\n","for idx in range(0,T,stepsize):\n","  t = torch.Tensor([idx]).type(torch.int64)\n","  plt.subplot(1, num_images+1, int((idx/stepsize) + 1))\n","\n","  image ,noise = forward_diffusion_sample(image,t)\n","  show_tensor_image(image)"],"metadata":{"id":"HSLsAVqx_l6K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Simulate forward diffusion\n","image = next(iter(dataloader))[0]\n","\n","plt.figure(figsize=(15,15))\n","plt.axis('off')\n","num_images = 10\n","stepsize = int(T/num_images)\n","\n","for idx in range(0, T, stepsize):\n","    t = torch.Tensor([idx]).type(torch.int64)\n","    plt.subplot(1, num_images+1, int((idx/stepsize) + 1))\n","\n","    image, noise = forward_diffusion_sample(image, t)\n","    show_tensor_image(image)"],"metadata":{"id":"kjdwwTquDATT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import nn\n","import math\n","class Block(nn.Module):\n","  def __init__(self,in_ch,out_ch,time_emb_dim,up=False):\n","    super().__init__()\n","    self.time_mlp = nn.Linear(time_emb_dim,out_ch)\n","    if up:\n","      self.conv1 = nn.Conv2d(2*in_ch,out_ch,3,padding=1)\n","      self.transform = nn.ConvTranspose2d(out_ch,out_ch,4,2,1)\n","    else:\n","      self.conv1 = nn.Conv2d(in_ch,out_ch,3,padding=1)\n","      self.transform = nn.Conv2d(out_ch,out_ch,4,2,1)\n","    self.conv2 = nn.Conv2d(out_ch,out_ch, 3,padding=1)\n","    self.bnorm1 = nn.BatchNorm2d(out_ch)\n","    self.bnorm2 = nn.BatchNorm2d(out_ch)\n","    self.relu = nn.ReLU()\n","  def forward(self,x,t,):\n","    # First conv\n","    h = self.bnorm1(self.relu(self.conv1(x)))\n","    # Time embedding\n","    time_emb = self.relu(self.time_mlp(t))\n","    # Extend last 2 dimentions\n","    time_emb = time_emb[(...,)+(None,)*2]\n","    # Add time channel\n","    h = h + time_emb\n","    # Second Conv\n","    h = self.bnorm2(self.relu(self.conv2(h)))\n","    # Down or Upsmaple\n","    return self.transform(h)\n","\n","\n","class SinusoidalPositionEmbeddings(nn.Module):\n","  def __init__(self,dim):\n","    super().__init__()\n","    self.dim = dim\n","  def forward(self,time):\n","    device = time.device\n","    half_dim = self.dim // 2\n","    embeddings = math.log(10000)/(half_dim-1)\n","    embeddings = torch.exp(torch.arange(half_dim,device=device)*-embeddings)\n","    embeddings = time[:,None]*embeddings[None,:]\n","    embeddings = torch.cat((embeddings.sin(),embeddings.cos()),dim=1)\n","    \n","    return embeddings\n","\n","\n","\n","class SimpleUnet(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    image_channels = 3\n","    down_channels = (64,128,256,512,1024)\n","    up_channels = (1024,512,256,128,64)\n","    out_dim = 1\n","    time_emb_dim = 32\n","    self.time_mlp = nn.Sequential(\n","        SinusoidalPositionEmbeddings(time_emb_dim),\n","        nn.Linear(time_emb_dim,time_emb_dim),\n","        nn.ReLU()\n","        )\n","    \n","    # Initial projection\n","\n","    self.conv0 = nn.Conv2d(image_channels,down_channels[0],3,padding=1)\n","    # Downsample\n","    self.downs = nn.ModuleList([Block(down_channels[i],down_channels[i+1],\\\n","                                   time_emb_dim) \\\n","                             for i in range(len(down_channels)-1)])\n","    # Upsample\n","    self.ups = nn.ModuleList([Block(up_channels[i],up_channels[i+1], \\\n","                                    time_emb_dim, up=True) \\\n","                              for i in range(len(up_channels)-1)])\n","    \n","    self.output = nn.Conv2d(up_channels[-1],3,out_dim)\n","\n","  def forward(self,x,timestep):\n","    # Embedd time\n","    t = self.time_mlp(timestep)\n","      \n","    # Initial conv\n","    x = self.conv0(x)\n","\n","    # Unet\n","    residul_inputs = []\n","\n","      \n","    for down in self.downs:\n","        x = down(x,t)\n","        residul_inputs.append(x)\n","    for up in self.ups:\n","        residul_x = residul_inputs.pop(x)\n","\n","        # Add residual x aaaaas additional channels\n","        x = torch.cat((x,residul_x),dim=1)\n","        x = up(x,t)\n","\n","    return self.output(x)\n","\n","model = SimpleUnet()\n","print('Num pasrasms:', sum(p.numel() for p in model.parameters()))\n","\n","model\n","\n","    \n","\n"],"metadata":{"id":"RJgnLyNmDYbM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import nn\n","import math\n","\n","\n","class Block(nn.Module):\n","    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n","        super().__init__()\n","        self.time_mlp =  nn.Linear(time_emb_dim, out_ch)\n","        if up:\n","            self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding=1)\n","            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)\n","        else:\n","            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n","            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)\n","        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n","        self.bnorm1 = nn.BatchNorm2d(out_ch)\n","        self.bnorm2 = nn.BatchNorm2d(out_ch)\n","        self.relu  = nn.ReLU()\n","        \n","    def forward(self, x, t, ):\n","        # First Conv\n","        h = self.bnorm1(self.relu(self.conv1(x)))\n","        # Time embedding\n","        time_emb = self.relu(self.time_mlp(t))\n","        # Extend last 2 dimensions\n","        time_emb = time_emb[(..., ) + (None, ) * 2]\n","        # Add time channel\n","        h = h + time_emb\n","        # Second Conv\n","        h = self.bnorm2(self.relu(self.conv2(h)))\n","        # Down or Upsample\n","        return self.transform(h)\n","\n","\n","class SinusoidalPositionEmbeddings(nn.Module):\n","    def __init__(self, dim):\n","        super().__init__()\n","        self.dim = dim\n","\n","    def forward(self, time):\n","        device = time.device\n","        half_dim = self.dim // 2\n","        embeddings = math.log(10000) / (half_dim - 1)\n","        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n","        embeddings = time[:, None] * embeddings[None, :]\n","        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n","        # TODO: Double check the ordering here\n","        return embeddings\n","\n","\n","class SimpleUnet(nn.Module):\n","    \"\"\"\n","    A simplified variant of the Unet architecture.\n","    \"\"\"\n","    def __init__(self):\n","        super().__init__()\n","        image_channels = 3\n","        down_channels = (64, 128, 256, 512, 1024)\n","        up_channels = (1024, 512, 256, 128, 64)\n","        out_dim = 1 \n","        time_emb_dim = 32\n","\n","        # Time embedding\n","        self.time_mlp = nn.Sequential(\n","                SinusoidalPositionEmbeddings(time_emb_dim),\n","                nn.Linear(time_emb_dim, time_emb_dim),\n","                nn.ReLU()\n","            )\n","        \n","        # Initial projection\n","        self.conv0 = nn.Conv2d(image_channels, down_channels[0], 3, padding=1)\n","\n","        # Downsample\n","        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i+1], \\\n","                                    time_emb_dim) \\\n","                    for i in range(len(down_channels)-1)])\n","        # Upsample\n","        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i+1], \\\n","                                        time_emb_dim, up=True) \\\n","                    for i in range(len(up_channels)-1)])\n","\n","        self.output = nn.Conv2d(up_channels[-1], 3, out_dim)\n","\n","    def forward(self, x, timestep):\n","        # Embedd time\n","        t = self.time_mlp(timestep)\n","        # Initial conv\n","        x = self.conv0(x)\n","        # Unet\n","        residual_inputs = []\n","        for down in self.downs:\n","            x = down(x, t)\n","            residual_inputs.append(x)\n","        for up in self.ups:\n","            residual_x = residual_inputs.pop()\n","            # Add residual x as additional channels\n","            x = torch.cat((x, residual_x), dim=1)           \n","            x = up(x, t)\n","        return self.output(x)\n","\n","model = SimpleUnet()\n","print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n","model"],"metadata":{"id":"AnJll7lclCkp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loss"],"metadata":{"id":"SlrBwlc6dW5L"}},{"cell_type":"code","source":["import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","def get_loss(model, x_0, t):\n","    x_noisy, noise = forward_diffusion_sample(x_0, t, device)\n","    noise_pred = model(x_noisy, t)\n","    return F.l1_loss(noise, noise_pred)"],"metadata":{"id":"_VUsGQzhdT3H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def sample_timestep(x,t):\n","  betas_t = get_index_from_list(betas,t,x.shape)\n","  sqrt_one_minus_alphas_cumprod_t = get_index_from_list(sqrt_one_minus_alphas_cumprod,t,x.shape)\n","  sqrt_recip_alphas_t = get_index_from_list(sqrt_recip_alphas,t,x.shape)\n","\n","  # call model (current image - noise prediction)\n","  model_mean = sqrt_recip_alphas_t*( \n","      x - betas_t * model(x,t) /sqrt_one_minus_alphas_cumprod_t\n","  )\n","  posterior_variance_t = get_index_from_list(posterior_variance,t,x.shape)\n","  if t ==0:\n","    return model_mean\n","  else:\n","    noise = torch.randn_like(x)\n","    return model_mean + torch.sqrt(posterior_variance_t)*noise\n","@torch.no_grad()\n","def sample_plot_image():\n","  # sample noise\n","  img = torch.randn((1,3,IMG_SIZE,IMG_SIZE),device=device)\n","  plt.figure(figsize=(15,15))\n","  plt.axis('off')\n","  num_images = 10\n","  stepsize = int(T/num_images)\n","  for i in range(0,T)[::-1]:\n","    t = torch.full((1,),i,device=device,dtype=torch.float)\n","    img = sample_timestep(img,t)\n","    if i % stepsize == 0:\n","      plt.subplot(1,num_images,i/stepsize+1)\n","      show_tensor_image(img.detach().cpu())\n","  plt.show()"],"metadata":{"id":"MbYg5iYxatKr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training "],"metadata":{"id":"i9MQK6WAic68"}},{"cell_type":"code","source":["from torch.optim import Adam\n","import time\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model.to(device)\n","optimizer = Adam(model.parameters(), lr=0.001)\n","epochs = 100 # Try more!\n","\n","for epoch in range(epochs):\n","    start_time = time.time() # measure start time of epoch\n","    for step, batch in enumerate(dataloader):\n","        optimizer.zero_grad()\n","\n","        t = torch.randint(0, T, (BATCH_SIZE,), device=device).long().to(torch.int64)\n","\n","        loss = get_loss(model, batch[0], t)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if epoch % 5 == 0 and step == 0:\n","            print(f\"Epoch {epoch} | step {step:03d} Loss: {loss.item()} \")\n","            sample_plot_image()\n","\n","    end_time = time.time() # measure end time of epoch\n","    epoch_time = end_time - start_time\n","    print(f\"Epoch {epoch} took {epoch_time:.2f} seconds\") # print time taken for epoch\n","\n"],"metadata":{"id":"9Sr0BAqviCGH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"V6rarLfNoEvt"},"execution_count":null,"outputs":[]}]}