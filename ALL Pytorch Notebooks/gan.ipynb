{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOtZ9Ji4RN2cylSBtv1wBGs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#dahyun+darwin= dahwin"],"metadata":{"id":"v_RCz7XxCjeF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_axWYXOWMh2x"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, in_features):\n","        super().__init__()\n","        self.disc = nn.Sequential(\n","            nn.Linear(in_features, 128),\n","            nn.LeakyReLU(0.01),\n","            nn.Linear(128, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        return self.disc(x)\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, z_dim, img_dim):\n","        super().__init__()\n","        self.gen = nn.Sequential(\n","            nn.Linear(z_dim, 256),\n","            nn.LeakyReLU(0.01),\n","            nn.Linear(256, img_dim),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, x):\n","        return self.gen(x)\n","# Hyperparameters etc.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","lr = 3e-4\n","z_dim = 64\n","image_dim = 28 * 28 * 1  # 784\n","batch_size = 32\n","num_epochs = 50\n","\n","disc = Discriminator(image_dim).to(device)\n","gen = Generator(z_dim, image_dim).to(device)\n","fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n","transforms = transforms.Compose(\n","    [\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,)),\n","    ]\n",")\n","\n","dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n","loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","opt_disc = optim.Adam(disc.parameters(), lr=lr)\n","opt_gen = optim.Adam(gen.parameters(), lr=lr)\n","criterion = nn.BCELoss()\n","step = 0\n","\n","for epoch in range(num_epochs):\n","    for batch_idx, (real, _) in enumerate(loader):\n","        real = real.view(-1, 784).to(device)\n","        batch_size = real.shape[0]\n","\n","        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n","        noise = torch.randn(batch_size, z_dim).to(device)\n","        fake = gen(noise)\n","        disc_real = disc(real).view(-1)\n","        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n","        disc_fake = disc(fake).view(-1)\n","        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n","        lossD = (lossD_real + lossD_fake) / 2\n","        disc.zero_grad()\n","        lossD.backward(retain_graph=True)\n","        opt_disc.step()\n","\n","        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n","        # where the second option of maximizing doesn't suffer from\n","        # saturating gradients\n","        output = disc(fake).view(-1)\n","        lossG = criterion(output, torch.ones_like(output))\n","        gen.zero_grad()\n","        lossG.backward()\n","        opt_gen.step()\n","\n","        if batch_idx == 0:\n","            print(\n","                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n","                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n","            )\n","\n","            with torch.no_grad():\n","                fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n","                data = real.reshape(-1, 1, 28, 28)\n","                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n","                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n","\n","                # Print the fake and real images to tensorboard\n","                # writer_fake.add_image(\n","                #     \"Mnist Fake Images\", img_grid_fake, global_step=step\n","                # )\n","                # writer_real.add_image(\n","                #     \"Mnist Real Images\", img_grid_real, global_step=step\n","                # )\n","                step += 1\n"]},{"cell_type":"code","source":["# after the training loop\n","torch.save(gen.state_dict(), \"generator.pth\")\n","                                                    "],"metadata":{"id":"9Y48PTNo8eKF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a new instance of the generator\n","gen = Generator(z_dim, image_dim).to(device)\n","\n","# load the saved state of the generator\n","gen.load_state_dict(torch.load(\"generator.pth\"))\n"],"metadata":{"id":"5jRxVx_MB8Ev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load the saved state of the generator\n","gen = Generator(z_dim, image_dim).to(device)\n","gen.load_state_dict(torch.load(\"generator.pth\"))\n","\n","# generate a batch of random noise vectors\n","num_images = 32\n","noise = torch.randn(num_images, z_dim).to(device)\n","\n","# generate fake images from the random noise\n","with torch.no_grad():\n","    fake = gen(noise).reshape(-1, 1, 28, 28)\n","\n","# visualize the generated images\n","import matplotlib.pyplot as plt\n","import numpy as np\n","img_grid = torchvision.utils.make_grid(fake, normalize=True)\n","plt.imshow(np.transpose(img_grid.cpu().numpy(), (1,2,0)))\n","plt.axis('off')\n","plt.show()\n"],"metadata":{"id":"XNcDTHykB_Tt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","from torchvision import transforms\n","with torch.no_grad():\n","    fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n","    data = real.reshape(-1, 1, 28, 28)\n","    img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n","\n","    # Create instance of ToPILImage transform\n","    to_pil = transforms.ToPILImage()\n","\n","    # Convert image tensor to PIL image\n","    pil_image = to_pil(img_grid_fake.cpu())\n","\n","    # Save PIL image as PNG file\n","    pil_image.save('dahwin.png')\n","\n"],"metadata":{"id":"4fwxTJTwCDzN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import IPython.display as display\n","\n","# Load the image\n","image = Image.open(\"dahwin.png\")\n","\n","# Display the image in the notebook\n","display.display(image)\n"],"metadata":{"id":"CBiyzqSjCNOF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"16HLufUlDjds"},"execution_count":null,"outputs":[]}]}