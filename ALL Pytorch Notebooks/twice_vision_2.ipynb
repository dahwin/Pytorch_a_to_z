{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"1lRNGaTOXfEmWiHkG6YY0wde4Z_nZwXet","authorship_tag":"ABX9TyP4O2CXcPzwt/rZhbJp0HAp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# dahyun+darwin = dahwin"],"metadata":{"id":"rdJP8Gkymi91"}},{"cell_type":"code","source":["import zipfile\n","from pathlib import Path\n","with zipfile.ZipFile('twice/dawin_data.zip','r') as zip_ref:\n","  print('Unzipping data')\n","  zip_ref.extractall()"],"metadata":{"id":"PHp-8bBWSjiB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pathlib\n","image_path = 'dawin_data'\n","\n","image_path = pathlib.Path(image_path)  \n","# Setup train and testing paths\n","train_dir = image_path / \"train\"\n","test_dir = image_path / \"test\"\n","\n","train_dir, test_dir"],"metadata":{"id":"-2p6fY5kSuMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NCg0I9rWR8tL"},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Define your data transformations\n","data_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","# Check if GPU is available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load your data\n","train_data = torchvision.datasets.ImageFolder(root=train_dir, transform=data_transform)\n","test_data = torchvision.datasets.ImageFolder(root=test_dir, transform=data_transform)\n","\n","# Define your CNN architecture\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n","        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n","        self.fc2 = nn.Linear(512, 6)  # change output size to 5\n","\n","    def forward(self, x):\n","        x = self.pool(nn.functional.relu(self.conv1(x)))\n","        x = self.pool(nn.functional.relu(self.conv2(x)))\n","        x = self.pool(nn.functional.relu(self.conv3(x)))\n","        x = x.view(-1, 64 * 28 * 28)\n","        x = nn.functional.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Create an instance of the CNN\n","net = Net().to(device)\n","\n","# Define your loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n","\n","# Define your data loaders\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False, num_workers=4)\n","\n","# Train your model\n","for epoch in range(10):\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader, 0):\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    print(f\"Epoch {epoch+1}, loss: {running_loss/len(train_data)}\")\n","\n","# Evaluate your model on the test set\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f\"Accuracy on test set: {100 * correct / total}%\")\n","\n"]},{"cell_type":"code","source":["from typing import Tuple ,Dict,List\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"id":"RiS2JQf8d5Vn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","# Download custom image\n","import requests\n","\n","# Setup custom image path\n","custom_image_path = pathlib.Path(\"dawin_data/ddubu.png\")\n","with open(custom_image_path, \"wb\") as f:\n","        # When downloading from GitHub, need to use the \"raw\" file link\n","        # request = requests.get(\"https://i.pinimg.com/564x/d6/46/2f/d6462fe5457ba4df288f859e9eaa2195.jpg\")\n","        request = requests.get(\"https://i.pinimg.com/564x/3f/7e/a5/3f7ea5e18fe4fe3bbb489e016ac7a66a.jpg\")\n","        print(f\"Downloading {custom_image_path}...\")\n","        f.write(request.content)"],"metadata":{"id":"-77_MdE5S81D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchvision\n","custom_image_uint8 = torchvision.io.read_image(str(custom_image_path)).type(torch.float32)\n","custom_image_uint8 = custom_image_uint8 / 255. \n","# Print out image data\n","print(f\"Custom image tensor:\\n{custom_image_uint8}\\n\")\n","print(f\"Custom image shape: {custom_image_uint8.shape}\\n\")\n","print(f\"Custom image dtype: {custom_image_uint8.dtype}\")"],"metadata":{"id":"6IdmJf4EZXNf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load in custom image and convert the tensor values to float32\n","custom_image = torchvision.io.read_image(str(custom_image_path)).type(torch.float32)\n","\n","# Divide the image pixel values by 255 to get them between [0, 1]\n","custom_image = custom_image / 255. \n","\n","# Print out image data\n","print(f\"Custom image tensor:\\n{custom_image}\\n\")\n","print(f\"Custom image shape: {custom_image.shape}\\n\")\n","print(f\"Custom image dtype: {custom_image.dtype}\")"],"metadata":{"id":"3k5Q5XAtZa6Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(custom_image.permute(1, 2, 0))"],"metadata":{"id":"Gv3wk_VxZa2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["custom_image_transform =  transforms.Compose([\n","    transforms.Resize((224,224))\n","])\n","custom_image_transformed = custom_image_transform(custom_image)\n","print(f\"Original shape:{custom_image.shape}\")\n","print(f\"New shape:{custom_image_transformed.shape}\")"],"metadata":{"id":"h8KKValXdu7p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(custom_image_transformed.permute(1, 2, 0))"],"metadata":{"id":"eYRZNR7KdxQ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","net.to(device)\n","custom_image_transformed = custom_image_transformed.to(device)\n","net.eval()\n","with torch.inference_mode():\n","    custom_image_pred = net(custom_image_transformed.unsqueeze(0))\n","custom_image_pred\n"],"metadata":{"id":"eHKiGwx4Zay1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pred_and_plot_image(model: torch.nn.Module, \n","                        image_path: str, \n","                        class_names: List[str] = None, \n","                        transform=None,\n","                        device: torch.device = device):\n","    \"\"\"Makes a prediction on a target image and plots the image with its prediction.\"\"\"\n","    \n","    # 1. Load in image and convert the tensor values to float32\n","    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n","    \n","    # 2. Divide the image pixel values by 255 to get them between [0, 1]\n","    target_image = target_image / 255. \n","    \n","    # 3. Transform if necessary\n","    if transform:\n","        target_image = transform(target_image)\n","    \n","    # 4. Make sure the model is on the target device\n","    model.to(device)\n","    \n","    # 5. Turn on model evaluation mode and inference mode\n","    model.eval()\n","    with torch.inference_mode():\n","        # Add an extra dimension to the image\n","        target_image = target_image.unsqueeze(dim=0)\n","    \n","        # Make a prediction on image with an extra dimension and send it to the target device\n","        target_image_pred = model(target_image.to(device))\n","        \n","    # 6. Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n","    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n","\n","    # 7. Convert prediction probabilities -> prediction labels\n","    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n","    \n","    # 8. Plot the image alongside the prediction and prediction probability\n","    plt.imshow(target_image.squeeze().permute(1, 2, 0)) # make sure it's the right size for matplotlib\n","    if class_names:\n","        title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n","    else: \n","      title = f\"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n","    plt.title(title)\n","    plt.axis(False);"],"metadata":{"id":"s_ltIh0VZavF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## MY FIRST AI MODEL WITH DAHYUN"],"metadata":{"id":"wpUoim7BeNKH"}},{"cell_type":"code","source":["# Pred on our custom image\n","pred_and_plot_image(model=net,\n","                    image_path=custom_image_path,\n","                    class_names=train_data.classes,\n","                    transform=custom_image_transform,\n","                    device=device)"],"metadata":{"id":"CtcgaV7qZarl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the entire model\n","PATH = 'model.pth'\n","torch.save(net, PATH)\n"],"metadata":{"id":"v3Z5Ai0leafx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save only the model's state dictionary\n","PATH = 'model_state_dict.pth'\n","torch.save(net.state_dict(), PATH)\n"],"metadata":{"id":"D--TnlyAmGjX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yPaicmKqmJKO"},"execution_count":null,"outputs":[]}]}