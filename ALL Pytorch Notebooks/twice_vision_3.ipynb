{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"15QgBDYOna2mtOdJR_4jv5LT4sAxK1GpB","authorship_tag":"ABX9TyPm5PR8BumjdyEWvIfek8Wr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"A-y3EJY_Keus"},"outputs":[],"source":["import zipfile\n","from pathlib import Path\n","with zipfile.ZipFile('twice/dawin_data.zip','r') as zip_ref:\n","  print('Unzipping data')\n","  zip_ref.extractall()"]},{"cell_type":"code","source":["!pip install vit_pytorch\n","!wget https://storage.googleapis.com/vit_models/imagenet21k/ViT-B_16.npz -P ./pretrained_models\n"],"metadata":{"id":"RMBWy20LM21Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pathlib\n","image_path = 'dawin_data'\n","\n","image_path = pathlib.Path(image_path)  \n","# Setup train and testing paths\n","train_dir = image_path / \"train\"\n","test_dir = image_path / \"test\"\n","\n","train_dir, test_dir"],"metadata":{"id":"EvCg2qOzMSMQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from vit_pytorch import ViT\n","import numpy as np\n","\n","# Define your data transformations\n","data_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","# Check if GPU is available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load your data\n","train_data = torchvision.datasets.ImageFolder(root=train_dir, transform=data_transform)\n","test_data = torchvision.datasets.ImageFolder(root=test_dir, transform=data_transform)\n","\n","# Load the ViT model\n","model = ViT(\n","    image_size = 224,\n","    patch_size = 32,\n","    num_classes = 6, # Change this to the number of classes in your dataset\n","    dim = 768,\n","    depth = 12,\n","    heads = 12,\n","    mlp_dim = 3072,\n","    dropout = 0.1,\n","    emb_dropout = 0.1\n",")\n","\n","# Load the saved model state from the .npz file\n","model.load_state_dict(np.load('model.npz'))\n","\n","# Move the model to the GPU\n","model = model.to(device)\n","\n","# Define your loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# Define your data loaders\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False, num_workers=4)\n","\n","# Train your model\n","for epoch in range(10):\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader, 0):\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    print(f\"Epoch {epoch+1}, loss: {running_loss/len(train_data)}\")\n","\n","# Evaluate your model on the test set\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f\"Accuracy on test set: {100 * correct / total}%\")\n","\n"],"metadata":{"id":"y2MaaLJhMKa4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SfGKCGXfN0CI"},"execution_count":null,"outputs":[]}]}