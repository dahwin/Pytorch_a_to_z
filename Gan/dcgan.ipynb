{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"18p5Vu-P0Fg3gF8yy06K1NKtQ2fAo4Jcw","authorship_tag":"ABX9TyOLgYMkRgAhdI/bn++Evyu5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oIW3dPzx4S9X"},"outputs":[],"source":["import torch\n","from torch import nn\n","class Discriminator(nn.Module):\n","  def __init__(self,channels_img,features_d):\n","    super(Discriminator,self).__init__()\n","    self.disc = nn.Sequential(\n","        # input : N x channels_img x 64 x 64\n","        nn.Conv2d(\n","            channels_img,\n","            features_d,\n","            kernel_size=4,\n","            stride=2,\n","            padding=1\n","        ),\n","        nn.LeakyReLU(0.2),\n","        self._block(features_d,features_d*2,4,2,1),# 16x16\n","        self._block(features_d*2,features_d*4,4,2,1), #  8x8\n","        self._block(features_d*4,features_d*8,4,2,1), # 4x4\n","        nn.Conv2d(features_d*8,1,kernel_size=4,stride=2,padding=0), # 1x1\n","        nn.Sigmoid()\n","\n","    )\n","  def _block(self,in_channels,out_channels,kernel_size,stride,padding):\n","    return nn.Sequential(\n","        nn.Conv2d(\n","            in_channels,\n","            out_channels,\n","            kernel_size,\n","            stride,\n","            padding,\n","            bias=False,\n","        ),\n","        nn.BatchNorm2d(out_channels),\n","        nn.LeakyReLU(0.2)\n","    )\n","  def forward(self,x):\n","    return self.disc(x)\n","class Generator(nn.Module):\n","  def __init__(self,z_dim,channles_img,features_g):\n","    super(Generator,self).__init__()\n","    self.gen = nn.Sequential(\n","        # input: N x z_dim x 1x1\n","        self._block(z_dim,features_g*16,4,1,0), # N x f_g*16*4*4\n","        self._block(features_g*16,features_g*8,4,2,1), # 8x8\n","        self._block(features_g*8,features_g*4,4,2,1), # 16 x 16\n","        self._block(features_g*4,features_g*2,4,2,1), # 32x32\n","        nn.ConvTranspose2d(\n","            features_g*2,channles_img,kernel_size=4,stride=2,padding=1\n","        ),\n","        nn.Tanh()\n","    )\n","  def _block(self,in_channels,out_channles,kernel_size,stride,padding):\n","    return nn.Sequential(\n","        nn.ConvTranspose2d(\n","            in_channels,\n","            out_channles,\n","            kernel_size,\n","            stride,\n","            padding,\n","          bias=False),\n","        nn.LazyBatchNorm2d(out_channles),\n","        nn.ReLU()\n","    )\n","  def forward(self,x):\n","    return self.gen(x)\n","\n","\n","def initialize_weights(model):\n","  for m in model.modules():\n","    if isinstance(m,(nn.Conv2d,nn.ConvTranspose2d,nn.BatchNorm2d)):\n","      nn.init.normal_(m.weight.data,0.0,0.02)\n","def test():\n","  N,in_channels,H,W = 0,3,64,64\n","  z_dim = 100\n","  x = torch.randn((N,in_channels,H,W))\n","  disc = Discriminator(in_channels,8)\n","  initialize_weights(disc)\n","  assert disc(x).shape == (N,1,1,1)\n","  gen = Generator(z_dim,in_channels,8)\n","  initialize_weights(gen)\n","  z = torch.randn(N,z_dim,1,1)\n","  assert gen(z).shape ==(N,in_channels,H,W)\n","test()"]},{"cell_type":"code","source":["!pip install TensorBoard==1.14\n"],"metadata":{"id":"FXUxMttvyS7M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","image_path = 'dawin_data'\n","image_path\n","\n","# Get list of all files and directories in image_path\n","all_files = os.listdir(image_path)\n","\n","# Loop through the list and print only directories\n","for file in all_files:\n","    if os.path.isdir(os.path.join(image_path, file)):\n","        print(file)\n","import zipfile\n","from pathlib import Path\n","with zipfile.ZipFile('twice/dawin_data.zip','r') as zip_ref:\n","  print('Unzipping data')\n","  zip_ref.extractall()\n","\n","import pathlib\n","image_path = pathlib.Path(image_path)  \n"],"metadata":{"id":"2V3dzKV8e6MK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !rm -r dawin_data/train/tuzyu"],"metadata":{"id":"a1Kq9VK3_VCm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup train and testing paths\n","train_dir = image_path / \"train\"\n","test_dir = image_path / \"test\"\n","\n","train_dir, test_dir\n","\n"],"metadata":{"id":"gWcuS8D9gRKn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import optim\n","import torchvision\n","from torchvision import datasets,transforms\n","from torch.utils.data import DataLoader\n","import torch\n","from torch import nn\n","from dcgan import Discriminator, Generator, initialize_weights\n","# Hyperparameters etc.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","larning_rate = 2e-4\n","batch = 128\n","image_size =64\n","channles_img = 3\n","z_dim = 100\n","NOISE_DIM = 100\n","num_epoch = 5\n","features_disc = 64\n","features_gen = 64\n","transforms = transforms.Compose(\n","    [\n","        transforms.Resize(image_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize(\n","            [0.5 for _ in range(channles_img)],[0.5 for _ in range(channles_img)]),\n","    ]\n",")\n","# dataset = datasets.MNIST(root='dataset/',train=True,transform=transforms,download=True)\n","dataset = datasets.ImageFolder(root=train_dir,transform=transforms,target_transform=None)\n","loader = DataLoader(dataset,batch,shuffle=True)\n","gen = Generator(NOISE_DIM,channles_img,features_gen).to(device)\n","disc = Discriminator(channles_img,features_disc).to(device)\n","initialize_weights(gen)\n","initialize_weights(disc)\n","opt_gen = optim.Adam(gen.parameters(),lr=larning_rate,betas=(0.5,0.999))\n","opt_disc =optim.Adam(disc.parameters(),lr=larning_rate,betas=(0.5,0.999))\n","criterion = nn.BCELoss()\n","fixed_noise = torch.randn(32,z_dim,1,1).to(device)\n","step=0\n","gen.train()\n","disc.train()\n","for epoch in range(0,num_epoch):\n","  for batch_idx,(real,_)in enumerate(loader):\n","    real = real.to(device)\n","    noise = torch.randn((batch,z_dim,1,1)).to(device)\n","    fake = gen(noise)\n","    ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n","    disc_real = disc(real).reshape(-1)\n","    loss_disc_real = criterion(disc_real,torch.zeros_like(disc_real))\n","    disc_fake = disc(fake).reshape(-1)\n","    loss_disc_fake = criterion(disc_fake,torch.zeros_like(disc_fake))\n","    loss_disc = (loss_disc_real+loss_disc_fake)/2\n","    disc.zero_grad()\n","    loss_disc.backward(retain_graph=True)\n","    opt_disc.step()\n","    ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n","    output = disc(fake).reshape(-1)\n","    loss_gen = criterion(output,torch.ones_like(output))\n","    gen.zero_grad()\n","    loss_gen.backward()\n","    opt_gen.step()\n","    if batch_idx == 0:\n","            print(\n","                f\"Epoch [{epoch}/{num_epoch}] Batch {batch_idx}/{len(loader)} \\\n","                      Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n","            )\n","\n","            with torch.no_grad():\n","                fake = gen(fixed_noise)\n","                img_grid_fake = torchvision.utils.make_grid(real, normalize=True)\n","                img_grid_real = torchvision.utils.make_grid(fake, normalize=True)\n","\n","                # Print the fake and real images to tensorboard\n","                # writer_fake.add_image(\n","                #     \"Mnist Fake Images\", img_grid_fake, global_step=step\n","                # )\n","                # writer_real.add_image(\n","                #     \"Mnist Real Images\", img_grid_real, global_step=step\n","                # )\n","                step += 1\n"],"metadata":{"id":"JB94p7j6CK4i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Training of DCGAN network on MNIST dataset with Discriminator\n","and Generator imported from models.py\n","Programmed by Aladdin Persson <aladdin.persson at hotmail dot com>\n","* 2020-11-01: Initial coding\n","* 2022-12-20: Small revision of code, checked that it works with latest PyTorch version\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","# from torch.utils.tensorboard import SummaryWriter\n","\n","\n","# Hyperparameters etc.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","LEARNING_RATE = 2e-4  # could also use two lrs, one for gen and one for disc\n","BATCH_SIZE = 128\n","IMAGE_SIZE = 64\n","CHANNELS_IMG = 1\n","NOISE_DIM = 100\n","NUM_EPOCHS = 5\n","FEATURES_DISC = 64\n","FEATURES_GEN = 64\n","\n","transforms = transforms.Compose(\n","    [\n","        transforms.Resize((64, 64)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(\n","            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n","        ),\n","    ]\n",")\n","\n","\n","# If you train on MNIST, remember to set channels_img to 1\n","dataset = datasets.MNIST(\n","    root=\"dataset/\", train=True, transform=transforms, download=True\n",")\n","\n","# comment mnist above and uncomment below if train on CelebA\n","# dataset = datasets.ImageFolder(root=\"celeb_dataset\", transform=transforms)\n","# dataset = datasets.ImageFolder(root=train_dir,transform=transforms)\n","dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n","gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n","disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\n","initialize_weights(gen)\n","initialize_weights(disc)\n","\n","opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n","opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n","criterion = nn.BCELoss()\n","\n","fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(device)\n","# writer_real = SummaryWriter(f\"logs/real\")\n","# writer_fake = SummaryWriter(f\"logs/fake\")\n","step = 0\n","\n","gen.train()\n","disc.train()\n","\n","for epoch in range(NUM_EPOCHS):\n","    # Target labels not needed! <3 unsupervised\n","    for batch_idx, (real, _) in enumerate(dataloader):\n","        real = real.to(device)\n","        noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n","        fake = gen(noise)\n","\n","        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n","        disc_real = disc(real).reshape(-1)\n","        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n","        disc_fake = disc(fake.detach()).reshape(-1)\n","        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n","        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n","        disc.zero_grad()\n","        loss_disc.backward()\n","        opt_disc.step()\n","\n","        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n","        output = disc(fake).reshape(-1)\n","        loss_gen = criterion(output, torch.ones_like(output))\n","        gen.zero_grad()\n","        loss_gen.backward()\n","        opt_gen.step()\n","\n","        # Print losses occasionally and print to tensorboard\n","        if batch_idx % 100 == 0:\n","            print(\n","                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n","                  Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n","            )\n","\n","            with torch.no_grad():\n","                fake = gen(fixed_noise)\n","                # take out (up to) 32 examples\n","                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n","                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n","\n","                # writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n","                # writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n","\n","            step += 1"],"metadata":{"id":"KMSkKB_hk9QJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# after the training loop\n","torch.save(gen.state_dict(), \"dahwin_dahyun.pth\")"],"metadata":{"id":"1HTmAJ-Tg53H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a new instance of the generator\n","gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN ).to(device)\n","\n","\n","# load the saved state of the generator\n","gen.load_state_dict(torch.load(\"dahwin_dahyun.pth\"))"],"metadata":{"id":"_Sh4r8A7g57O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision\n","from torchvision.utils import save_image\n","\n","# Define the hyperparameters\n","NOISE_DIM = 100\n","channles_img = 1\n","features_gen = 64\n","image_size = 64\n","\n","# Create a new instance of the generator\n","gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN ).to(device)\n","\n","# Load the saved state of the generator\n","gen.load_state_dict(torch.load(\"dahwin_dahyun.pth\"))\n","\n","# Generate 64 images\n","num_images = 64\n","noise = torch.randn(num_images, NOISE_DIM, 1, 1).to(device)\n","generated_images = gen(noise)\n","\n","# Save the generated images to a file\n","save_image(generated_images, \"generated_images.png\", nrow=8, normalize=True)\n","\n","# Display the generated images\n","from PIL import Image\n","im = Image.open(\"generated_images.png\")\n","im.show()\n"],"metadata":{"id":"pzyAkB5_g6O3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a new instance of the generator\n","gen = Generator(NOISE_DIM, channles_img, features_gen).to(device)\n","\n","# load the saved state of the generator\n","gen.load_state_dict(torch.load(\"dahwin_dahyun.pth\"))\n","\n","# generate a batch of random noise vectors\n","num_images = 32\n","noise = torch.randn(num_images, NOISE_DIM, 1, 1).to(device)\n","\n","# generate fake images from the random noise\n","with torch.no_grad():\n","    fake = gen(noise)\n","\n","# visualize the generated images\n","import matplotlib.pyplot as plt\n","import numpy as np\n","img_grid = torchvision.utils.make_grid(fake, normalize=True)\n","plt.imshow(np.transpose(img_grid.cpu().numpy(), (1,2,0)))\n","plt.axis('off')\n","plt.show()\n"],"metadata":{"id":"7g8MUeWwg6Sf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir logs\n"],"metadata":{"id":"j84b6cF3kx55"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir logs"],"metadata":{"id":"I2RAo0ChNVWa"},"execution_count":null,"outputs":[]}]}